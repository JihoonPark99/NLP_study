{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JihoonPark99/NLP_study/blob/main/_4_%EB%AC%B8%EC%84%9C_%EB%B6%84%EB%A5%98(Document_Classification).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meRAQbe3ArB7"
      },
      "source": [
        "# 문서 분류(Document Classification)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myxaNrtIl7Z0"
      },
      "source": [
        "## 데이터 준비"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e85EZuHb-Z9f"
      },
      "source": [
        "* 문서 분류에 필요한 데이터는 `scikit-learn`이 제공하는 20개의 주제를 가지는 뉴스그룹 데이터를 사용\n",
        "* 텍스트는 `CounterVectorizer`를 거쳐 DTM 행렬로 변환\n",
        "* DTM 행렬은 문서에 등장하는 단어들을 빈도 수 별로 표현한 행렬 'Document Term Matrix'\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYsGQgxCl-kQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab085888-864e-4cf7-fb9f-11b6be7a2937"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "news = fetch_20newsgroups()\n",
        "\n",
        "x = news.data\n",
        "y = news.target\n",
        "\n",
        "cv = CountVectorizer()\n",
        "x = cv.fit_transform(x)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3)\n",
        "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7919, 130107) (3395, 130107) (7919,) (3395,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iRARmcl_EmI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cec1c957-91ba-4536-c82f-618888fa528f"
      },
      "source": [
        "print(x_train[0])\n",
        "# (0번째문서, n번째 인덱스를 가지는 값) n'번 등장했다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 56979)\t1\n",
            "  (0, 111322)\t1\n",
            "  (0, 114731)\t2\n",
            "  (0, 87620)\t1\n",
            "  (0, 95162)\t1\n",
            "  (0, 64095)\t1\n",
            "  (0, 90379)\t1\n",
            "  (0, 76032)\t1\n",
            "  (0, 28615)\t1\n",
            "  (0, 114455)\t1\n",
            "  (0, 115475)\t1\n",
            "  (0, 66608)\t1\n",
            "  (0, 73201)\t1\n",
            "  (0, 90252)\t1\n",
            "  (0, 128402)\t1\n",
            "  (0, 62221)\t1\n",
            "  (0, 94362)\t1\n",
            "  (0, 88363)\t1\n",
            "  (0, 119451)\t1\n",
            "  (0, 25399)\t2\n",
            "  (0, 75901)\t1\n",
            "  (0, 108799)\t1\n",
            "  (0, 58830)\t1\n",
            "  (0, 51268)\t2\n",
            "  (0, 70010)\t1\n",
            "  :\t:\n",
            "  (0, 60150)\t2\n",
            "  (0, 39415)\t3\n",
            "  (0, 48351)\t1\n",
            "  (0, 26085)\t1\n",
            "  (0, 93582)\t1\n",
            "  (0, 67186)\t1\n",
            "  (0, 27721)\t1\n",
            "  (0, 128084)\t1\n",
            "  (0, 33331)\t2\n",
            "  (0, 92999)\t1\n",
            "  (0, 121265)\t1\n",
            "  (0, 3802)\t1\n",
            "  (0, 56195)\t1\n",
            "  (0, 96852)\t1\n",
            "  (0, 67796)\t1\n",
            "  (0, 68253)\t1\n",
            "  (0, 86694)\t1\n",
            "  (0, 114309)\t1\n",
            "  (0, 67670)\t1\n",
            "  (0, 50695)\t2\n",
            "  (0, 64171)\t2\n",
            "  (0, 96697)\t1\n",
            "  (0, 38213)\t3\n",
            "  (0, 33859)\t2\n",
            "  (0, 95031)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGM2WbEdAsGL"
      },
      "source": [
        "## scikit-learn을 이용한 문서 분류"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7g4PrqerCkj"
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnww8xssA-FL"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgUTDK7o9wC6"
      },
      "source": [
        ":* Logistic Regression은 특성상 다중 분류에는 적합하지 않음\n",
        "- 여기서 사용할 순 없음.우린 20개의 클래스가 있기 때문문"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rk3jq9p9DCcv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b0594ec-3132-4928-9cda-3f1eefc221b3"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "LR = LogisticRegression()\n",
        "LR.fit(x_train, y_train)\n",
        "pred = LR.predict(x_test)\n",
        "acc = accuracy_score(pred, y_test)\n",
        "print(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8733431516936672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4g1mEefA-SU"
      },
      "source": [
        "### 나이브 베이즈 분류기(Naive Bayes Classification)\n",
        "- 베이즈 정리를 적용한 확률적 분류 알고리즘\n",
        "- 모든 특성들이 독립임을 가정(naive 가정)\n",
        "- 입력 특성에 따라 3개의 분류기 존재\n",
        "  - 가우시안 나이브 베이즈 분류기\n",
        "  - 베리누이 나이브 베이즈 분류기\n",
        "  - 다항 나이브 베이즈 분류기\n",
        "- https://angeloyeo.github.io/2020/01/09/Bayes_rule."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcIkL0Bx-AIG"
      },
      "source": [
        "#### DTM을 이용한 Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogbxoPS0DMTd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86bb6f6f-4da2-4a0a-b9a8-5ed3767722d6"
      },
      "source": [
        "##우리는 다항 나이브베이즈 분류기를 사용할것임\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "NB = MultinomialNB()\n",
        "NB.fit(x_train, y_train)\n",
        "pred = NB.predict(x_test)\n",
        "acc = accuracy_score(pred,y_test)\n",
        "print(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8309278350515464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZC7kjWt961H"
      },
      "source": [
        "#### tf-idf를 이용한 정확도 향상"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2j7cZc71yiJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1dcfb1d-44c7-4b90-99a9-eff0ae397e85"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "##x_train과 x_test를 tf-idf로 바꿔주기기\n",
        "tfidf = TfidfTransformer()\n",
        "x_train_tf = tfidf.fit_transform(x_train)\n",
        "x_test_tf = tfidf.fit_transform(x_test)\n",
        "\n",
        "##바꾼것으로 학습 하기 \n",
        "NB.fit(x_train_tf, y_train)\n",
        "pred = NB.predict(x_test_tf)\n",
        "acc = accuracy_score(pred, y_test)\n",
        "print(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8394698085419735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1D0CGeJTA-ZH"
      },
      "source": [
        "### Support Vector Machine"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 회귀,분류,이상치 탐지 등에 사용되는 지도학습 방법\n",
        "- 클래스 사이의 경계에 위치한 데이터포인트를 서포트 벡터(support vector)라고 함\n",
        "- 각 서포트 벡터가 클래스 사이의 결정경계를 구분하는데 얼마나 중요한지를 복습\n",
        "- 각 서포트 벡터 사이의 마진이 가장 큰 방향으로 학습\n",
        "- 서포트 벡터 까지의 거리와 서포트 벡터의 중요성을 기반으로 예측을 수행행\n",
        "- https://hleecaster.com/ml-svm-concept/"
      ],
      "metadata": {
        "id": "RrhQNH-UEzXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###SVM공부\n",
        "from sklearn.svm import SVC\n",
        "classifier = SVC(kernel = 'linear')\n",
        "training_points = [[1, 2], [1, 5], [2, 2], [7, 5], [9, 4], [8, 2]]\n",
        "labels = [1, 1, 1, 0, 0, 0]\n",
        "classifier.fit(training_points, labels) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrUE7j6T9skH",
        "outputId": "2ff72753-3b27-42dc-de04-093d1dda72bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear')"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##분류됐는지 확인\n",
        "print(classifier.predict([[3, 2]]))\n",
        "\n",
        "##서포트벡터 확인\n",
        "print(classifier.support_vectors_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQ21tkOX93BH",
        "outputId": "0aadd763-ba43-4110-dfdd-bdafb4d365d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\n",
            "[[7. 5.]\n",
            " [8. 2.]\n",
            " [2. 2.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##이상치 허용\n",
        "classifier = SVC(C = 0.01)\n",
        "#기본값은 1\n",
        "#당연히 C의 최적 값은 데이터에 따라 다르다. 결국 여러가지 C값을 넣어보면서 모델을 검증하는 수밖에 없다."
      ],
      "metadata": {
        "id": "pwrJFli9_3ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#선형데이터가 아닐땐, kernel을 지정해서 해결하자!!\n",
        "from sklearn.svm import SVC\n",
        "classifier = SVC(kernel = 'poly')"
      ],
      "metadata": {
        "id": "PmTg3uVGAE5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxxK92DGDpyL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c105696-8a6e-457c-e3ec-6606fa285df4"
      },
      "source": [
        "from sklearn import svm\n",
        "\n",
        "SVM = svm.SVC(kernel='linear')\n",
        "SVM.fit(x_train, y_train)\n",
        "pred = SVM.predict(x_test)\n",
        "acc = accuracy_score(pred, y_test)\n",
        "print(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8300441826215023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPeounJWA-e6"
      },
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 분류와 회귀에 사용되는 지도 학습 방법\n",
        "- 데이터 특성으로 부터 추론된 결정 규칙을 통해 값을 예측\n",
        "- if-then-else 결정규칙을 통해 데이터 학습\n",
        "- 트리의 깊이가 깊을수록 복잡한 모델"
      ],
      "metadata": {
        "id": "4EANNfF-K_6y"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62wyoby4EEDb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69cd2118-ae10-43ee-b44d-249b9fa344db"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "import graphviz\n",
        "DT = DecisionTreeClassifier()\n",
        "DT.fit(x_train, y_train)\n",
        "pred = DT.predict(x_test)\n",
        "acc = accuracy_score(pred, y_test)\n",
        "print(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6185567010309279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# ## Plot Tree with plot_tree\n",
        "# fig = plt.figure(figsize=(15, 8))\n",
        "# DT.plot_tree"
      ],
      "metadata": {
        "id": "krv-H59pEMex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeEPOjxxA-my"
      },
      "source": [
        "### XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 트리가반의 앙상블 기법\n",
        "- 분류에 있어서 다른 알고리즘보다 좋은 예측 성능을 보여줌\n",
        "- XGBoost는 GBM기반이지만, GBM의 단점인 느린 수행시간과 과적합 규제 부재 등의 문제를 해결\n",
        "- 병렬CPU환경에서 빠르게 학습 가능\n"
      ],
      "metadata": {
        "id": "i-blH1odL2qp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4TAgLK5ECCi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f96c0d38-1b38-4dcc-fa22-128a8910eb57"
      },
      "source": [
        "\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb = XGBClassifier(n_estimtors = 30, \n",
        "                    learning_rate=0.05,\n",
        "                    max_depth = 3)\n",
        "xgb.fit(x_train, y_train)\n",
        "pred = xgb.predict(x_test)\n",
        "acc = accuracy_score(pred, y_test)\n",
        "print(acc)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7737849779086893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1b4PWPBAWwn"
      },
      "source": [
        "##교차 검증"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd7AexinGlYP"
      },
      "source": [
        "* 일반 검증은 학습 데이터가 테스트 데이터로 사용되지 않음\n",
        "* 교차 검증은 데이터를 n개의 집합으로 나누어 정확도를 계산해 학습 데이터로 사용된 데이터도 테스트 데이터로 사용\n",
        "* 교차 검증을 사용하면 일반 검증보다 모델의 일반화가 잘 되어 있는지 평가 가능\n",
        "* 앞서 구성한 나이브 베이즈 모델을 교차 검증"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzaiICzaHrI7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5628dbb3-da3f-498e-f23e-993c63538a13"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(NB,x,y,cv=5)\n",
        "print(scores, scores.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.83870968 0.83826779 0.82368537 0.83031374 0.83642794] 0.833480903927519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVQBNi5lIn3X"
      },
      "source": [
        "* 교차 검증을 통해 일반 검증보다 좀 더 일반화된 모델 생성 가능\n",
        "* 교차 검증은 일반 검증에 비해 n번 검증을 해 비용이 더 많이 소요"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqIU3r_9AZQm"
      },
      "source": [
        "## 정밀도와 재현률 "
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wi0FxIlUQhVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5C0ZPgKLJSvt"
      },
      "source": [
        "\n",
        "\n",
        "# 코드로 형식 지정됨\n",
        "\n",
        "\n",
        "* 정밀도(precision)는 양성 클래스(정답)으로 예측한 샘플이 양성 클래스일 확률을 의미\n",
        "* 모델이 얼마나 양성 클래스를 잘 예측하는지를 나타냄\n",
        "* 재현률(recall)은 양성 클래스인 샘플에서 모델이 양성 클래스로 예측한 샘플 비율을 의미하며, 모델이 얼마나 실제 상황을 재현하는지를 나타냄\n",
        "* 정밀도와 재현율의 가중조화평균인 F1-score라는 지표는 정확도에 비해 더 효과적인 모델 분석 지표로 알려져 있음\n",
        "* 직접 계산할 수도 있으나, scikit-learn은 이를 편리하게 계산해주는 함수를 제공"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3hObzsrNuzF"
      },
      "source": [
        "* 다중 클래스 분류 문제에서 정밀도와 재현률을 계산할 때는 클래스간의 지표를 어떻게 합칠지 지정 필요\n",
        "\n",
        "  * None - 클래스간 지표를 합치지 말고 그대로 출력\n",
        "  * micro - 정밀도와 재현률이 같음, 이로 인해 f1-score도 정밀도, 재현률과 동일\n",
        "  * macro - 클래스간 지표를 단순 평균한 값\n",
        "  * weighted - 클래스간 지표를 가중 평균한 값"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98npJWW8J9Px",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c2e3427-3488-4f1a-d673-8c65a3114a47"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "precision = precision_score(pred, y_test, average='macro')\n",
        "recall = recall_score(pred, y_test, average='macro')\n",
        "f1 = f1_score(pred, y_test, average='macro')\n",
        "print(precision, recall, f1)\n",
        "\n",
        "#micro : 값3개 다 똑같이 나옴\n",
        "#macro : 값3개 각각 다르게 나옴옴"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7688605980687239 0.7880789968023558 0.7738267333256023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JPcMoD0NQi6"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QY3s-EXdArpC"
      },
      "source": [
        "## 그리드 검색을 이용한 파라미터 최적화"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0rY-TxKCsOi"
      },
      "source": [
        "* 그리드 검색을 사용하면 분류기에 사용하는 파라미터 최적화 가능\n",
        "* 그리드 검색을 통해 앞서 구성한 나이브 베이즈 모델의 'alpha' 파라미터를 최적화시키는 예제"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOkeA7siDdvF"
      },
      "source": [
        "* `estimator`: 사용 모델 객체     \n",
        "* `param_grid`: 사용 객체:지정 파라미터 리스트로 구성된 딕셔너리    \n",
        "* `scoring`: 최적화하고자 하는 성능 지표   \n",
        "* `cv`: 교차 검증 분할 개수      "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCheUO9YBgRi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6d60a5e-9d80-4e78-997a-c5694af93c8e"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "GS = GridSearchCV(estimator=NB, param_grid={\n",
        "    'alpha' : [0.001, 0.01, 0.1, 1.]},\n",
        "    scoring = 'accuracy',\n",
        "    cv = 10\n",
        ")\n",
        "\n",
        "GS.fit(x_train, y_train)\n",
        "print(GS.best_score_)\n",
        "print(GS.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8754879707313336\n",
            "{'alpha': 0.001}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "GS = GridSearchCV(estimator=NB, param_grid={\n",
        "    'alpha' : [0.001, 0.002, 0.003, 0.0005]},\n",
        "    scoring = 'accuracy',\n",
        "    cv = 10\n",
        ")\n",
        "\n",
        "GS.fit(x_train, y_train)\n",
        "print(GS.best_score_)\n",
        "print(GS.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bH2RiKqcP83r",
        "outputId": "af3d2fc1-b3ac-4f12-f7d1-a3eebd31a05b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8763716494911187\n",
            "{'alpha': 0.0005}\n"
          ]
        }
      ]
    }
  ]
}
