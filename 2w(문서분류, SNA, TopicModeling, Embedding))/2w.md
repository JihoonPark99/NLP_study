# 2w NLP
1. 4강 문서분류
2. 5강 의미연결망 분석
3. 6강 토픽모델링 
4. 7강 임베딩

--- 

# 문서분류
20개의 주제를 가지는 데이터를 이용해 문서분류

- 1.로지스틱 회귀  
>  - 여러 속성들을 바탕으로 어떤 사건의 발생 가능성을 예측하는 방법

- 2.서포트 벡터 머신
> - 각 서포트 벡터 사이의 마진이 가장 큰 방향으로 학습

- 3.나이브 베이즈 분류기
> - 베이즈 정리를 이용한 확률적 기계학습 알고리즘

- 4.결정트리
> - 데이터 특성으로부터 추론된 결정규칙을 통해 값을 예측

- 5.XGBoost 
> - 트리 기반 앙상블 기법 

- 6.교차검증
> - n개의 집합으로 나누어 정확도를 계산

- 7.정밀도와 재현율 & F1-score

- 8.그리드 검색을 이용한 파라미터 최적화 
> - 파라미터 값을 여러개 주고 가장 좋은 파라미터 값에 대한 결과를 받음


## [문서분류 정리 블로그](https://jihoonjihoon.tistory.com/16)
----

# 의미연결망 분석

- n-gram
- 동시출현빈도분석
- 중심성
    - 연결중심성
    - 위세중심성
    - 근접중심성
    - 매개중심성
- pagerank

## [의미연결망 정리 블로그](https://jihoonjihoon.tistory.com/15)
> 작성중...

---- 

# 토픽모델링 
문서 집합에 숨어 있는 ‘주제’를 찾아내는 텍스트 마이닝기법 중 하나

- 문서에 함축되어 있는 주요 주제를 효과적으로 찾아낼 수 있습니다.

- 토픽 모델링에 자주 사용되는 기법

## 잠재 의미 분석 : LSA(Latent Semantic Analysis)

- 기존의 카운트 기반 벡터화나 TF-IDF를 통해 만든 문서-단어 행렬(Document Term Matrix, DTM)은 단어의 빈도수를 이용해서 행렬을 만들었습니다.

- 하지만, 단어의 빈도 수로는 문서의 주제를 찾을 수 없습니다.

- 그래서 문서의 잠재 의미를 찾아내는 것입니다.  즉 잠재 의미 분석을 통해 “이 글의 주제”를 찾는 것입니다.

> 가정1. 문서는 여러 개의 토픽을 지닐 수 있고 한 문서는 특정 토픽을 얼마나 지녔는지의 확률 벡터로 표현된다.

> 가정2. 하나의 토픽은 해당 토픽에서 이용되는 단어의 비율로 표현된다.

> 가정3. 한 문서에서 특정 단어들이 이용될 가능성은 위의 두 확률 분포의 곱으로 표현합니다.

## 잠재 디리클레 할당: LDA(Latent Dirichlet Allocation)

- 문서들은 토픽들의 혼합으로 구성되어져 있으며, 토픽들은 확률 분포에 기반해 단어들을 생성한다고 가정합니다. 데이터가 주어지면, LDA는 문서가 생성된는 과정을 역추적합니다.

- 모델의 학습할 패러메터의 개수를 줄여 over-fitting 을 방지하고, 새로운 문서에 대한 topic vector 를 inference 할 수 있도록 개선한 모델

### LSA와 LDA의 차이

> LSA : DTM을 차원 축소 하여 축소 차원에서 근접 단어들을 토픽으로 묶는다.

> LDA : 단어가 특정 토픽에 존재할 확률과 문서에 특정 토픽이 존재할 확률을 결합확률로 추정하여 토픽을 추출한다.

## [Topic Modeling 블로그 정리](https://jihoonjihoon.tistory.com/17)

----
 
# 임베딩
- word2vec
> 자세한 설명은 ppt에서 진행

## 자세한 내용 ppt참조!!
































